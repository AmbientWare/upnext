---
title: Workers
description: The core service that processes background jobs from a Redis queue.
icon: gears
sidebarTitle: Overview
---

```python
import upnext

worker = upnext.Worker("my-worker", concurrency=10)

@worker.task(retries=3, timeout=30.0)
async def process_order(order_id: str, items: list[str]) -> dict:
    return {"order_id": order_id, "status": "completed"}

@worker.cron("0 9 * * *")
async def daily_report():
    return {"generated": True}

order_placed = worker.event("order.placed")

@order_placed.on
async def send_confirmation(order_id: str):
    return {"sent": True}
```

A **Worker** listens on a Redis queue and executes jobs. You define all three job types — [tasks](/concepts/tasks), [events](/concepts/events), and [cron jobs](/concepts/cron-jobs) — on a worker instance.

## Create a worker

Instantiate `upnext.Worker` to create a worker:

```python
worker = upnext.Worker(
    "my-worker",        # Name (used for identification in dashboard)
    concurrency=10,     # Max concurrent jobs (default: 2)
)
```

A worker manages:
- A Redis-backed queue for receiving jobs
- A job processor that executes task, event, and cron functions
- Cron schedulers for recurring work
- Event routers for pub/sub handlers

## Worker options

| Parameter | Type | Default | Description |
| --- | --- | --- | --- |
| `name` | `str` | auto-generated | Worker name for dashboard identification |
| `concurrency` | `int` | `2` | Maximum concurrent job executions |
| `profile` | `WorkerProfile` | `ProfileOptions.SAFE` | Queue tuning profile (see [Queue tuning](#queue-tuning)) |
| `sync_executor` | `SyncExecutor` | `THREAD` | Executor for sync tasks: `THREAD` or `PROCESS` |
| `redis_url` | `str` | `None` | Redis URL (falls back to `UPNEXT_REDIS_URL` env var) |
| `secrets` | `list[str]` | `[]` | Secret names to fetch on startup (requires server) |

## Queue tuning

Workers use a `WorkerProfile` to control queue batch sizes, buffer capacities, and stream limits. The default profile is `ProfileOptions.SAFE`.

```python
import upnext

# Use the throughput preset for high-volume workloads
worker = upnext.Worker("my-worker", profile=upnext.ProfileOptions.THROUGHPUT)

# Or create a custom profile
worker = upnext.Worker(
    "my-worker",
    profile=upnext.WorkerProfile(batch_size=500, inbox_size=5000),
)
```

### Built-in presets

| Preset | `batch_size` | `inbox_size` | `outbox_size` | `flush_interval_ms` | `stream_maxlen` |
| --- | --- | --- | --- | --- | --- |
| `ProfileOptions.SAFE` | 100 | 1,000 | 10,000 | 5.0 | 0 (unbounded) |
| `ProfileOptions.THROUGHPUT` | 200 | 2,000 | 20,000 | 20.0 | 200,000 |

You can also subclass `WorkerProfile` to create your own reusable presets:

```python
class HighVolumeProfile(upnext.WorkerProfile):
    batch_size: int = 500
    inbox_size: int = 5000
    stream_maxlen: int = 500_000

worker = upnext.Worker("my-worker", profile=HighVolumeProfile())
```

## Run a worker

Workers are started with `upnext.run()` or the CLI:

```python
# In code
upnext.run(worker)
```

```bash
# From the CLI
upnext run service.py
```

<Tip>
See the [Run Services guide](/guides/run-services) for running workers alongside APIs, using `--only` to start specific components, and more.
</Tip>

## Scaling

Run multiple worker instances pointing at the same Redis — UpNext distributes jobs automatically.

```bash
# Terminal 1
upnext run service.py

# Terminal 2 (same code, same Redis)
upnext run service.py
```

Under the hood, UpNext uses **Redis Streams consumer groups**. Each worker instance joins the same consumer group and claims jobs via `XREADGROUP`, so no two workers process the same job. If a worker crashes, its pending jobs are automatically recovered by other instances.

Each instance manages its own concurrency independently:

```python
# Each instance processes up to 50 jobs at a time
worker = upnext.Worker("my-worker", concurrency=50)
```

Per-function controls like `rate_limit` and `max_concurrency` are enforced **across the entire cluster**, not per-instance — so `max_concurrency=10` means 10 total, regardless of how many workers are running.

<Tip>
See the [Docker Compose guide](/deploy/docker-compose) for scaling workers with container replicas.
</Tip>

## Job types

Workers execute three kinds of jobs. Each has its own decorator and behavior:

<CardGroup cols={3}>
  <Card title="Tasks" icon="list-check" href="/concepts/tasks">
    One-off background jobs with retries, timeouts, and result handling.
  </Card>
  <Card title="Events" icon="bell" href="/concepts/events">
    Pub/sub handlers that trigger when an event is published.
  </Card>
  <Card title="Cron Jobs" icon="clock" href="/concepts/cron-jobs">
    Recurring jobs on a schedule with standard cron syntax.
  </Card>
</CardGroup>

Tasks can submit other tasks, creating parent-child relationships that form multi-step workflows. UpNext automatically tracks the full execution tree — see [Workflows](/concepts/workflows).
